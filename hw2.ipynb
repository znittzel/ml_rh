{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\qquad$ $\\qquad$$\\qquad$  **TDA 231 Machine Learning: Homework 2** <br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$ **Goal: Classification**<br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$                   **Grader: Divya** <br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$                     **Due Date: 23/4** <br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$                   **Submitted by: Name, Personal no., email** <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General guidelines:\n",
    "* All solutions to theoretical problems, can be submitted as a single file named *report.pdf*. They can also be submitted in this ipynb notebook, but equations wherever required, should be formatted using LaTeX math-mode.\n",
    "* All discussion regarding practical problems, along with solutions and plots should be specified here itself. We will not generate the solutions/plots again by running your code.\n",
    "* Your name, personal number and email address should be specified above and also in your file *report.pdf*.\n",
    "* All datasets can be downloaded from the course website.\n",
    "* All tables and other additional information should be included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theoretical problems\n",
    "\n",
    "## [Naive Bayes Classifier, 6 points]\n",
    "\n",
    "A psychologist does a small survey on ''happiness''. Each respondent provides a vector with entries 1 or 0 corresponding to if they answered “yes” or “no” to a question respectively. The question vector has attributes \n",
    "$$\n",
    "x = (\\mbox{rich, married, healthy}) \\tag{1}\n",
    "$$\n",
    "\n",
    "Thus a response $(1, 0, 1)$ would indicate that the respondent was\n",
    "''rich'', ''unmarried'' and ''healthy''. In addition, each respondent\n",
    "gives a value $c = 1$ if they are content wih their life and $c = 0$\n",
    "if they’re not. The following responses were obtained.\n",
    "\n",
    "$$\n",
    "c = 1: (1, 1, 1),(0, 0, 1),(1, 1, 0),(1, 0, 1) \\\\\n",
    "c = 0: (0, 0, 0),(1, 0, 0),(0, 0, 1),(0, 1, 0)\n",
    "$$\n",
    "\n",
    "# ---------------------------------- Answer 1.1 ---------------------------------------\n",
    "1. Using naive Bayes, what is the probability that a person who is ''not rich'', ''married'' and ''healthy'' is ''content''?\n",
    "\n",
    "Let C=Content, R=Rich, M=Married and H=Healthy. Let X=(0,1,1). First, calculate each feature given C=1:\n",
    "\n",
    "$$ P(R=0 \\mid C=1) = 1/4 \\\\ P(M=1 \\mid C=1) = 2/4 \\\\ P(H=1 \\mid C=1) = 3/4 $$\n",
    "\n",
    "Now, let's calculate that X obtain those values, given C=1, and multiply with P(C=1) (denominator of Bayes rule)\n",
    "\n",
    "$$ P(x=X \\mid C=1)P(C=1) = \\frac{1}{4} * \\frac{2}{4} * \\frac{3}{4} = \\frac{3}{64} $$\n",
    "\n",
    "and continue with the nominator, P(X)\n",
    "\n",
    "$$P(x=X)=P(R=0)P(M=1)P(H=1)=\\frac{4}{7}*\\frac{3}{8}*\\frac{4}{8}=\\frac{3}{32}$$\n",
    "\n",
    "Finally, we calculate\n",
    "\n",
    "$$ P(C=1 \\mid X)=\\frac{P(x=X \\mid C=1)P(C=1)}{P(x=X)}=\\frac{3/64}{3/32}=\\frac{1}{2} $$\n",
    "\n",
    "# ---------------------------------- Answer 1.2 ---------------------------------------\n",
    "2. What is the probability that a person who is ''not rich'' and ''married'' is content ? (i.e. we do not know if they are ''healthy'')\n",
    "\n",
    "Let's perform the same algorithm as in 1. but excluding the healthy-feature. Let y be a 2D vector variable obtaining values $(i,j) \\in \\mathbb{R}^2$, where $Rich=i$ and $Married=j$ and Y=(0,1).\n",
    "\n",
    "$$P(y=Y \\mid C=1)P(C=1)=P(R=0 \\mid C=1)P(M=1 \\mid C=1)P(C=1)=\\frac{1}{4}*\\frac{2}{4}\\frac{1}{2}=\\frac{1}{16}$$\n",
    "\n",
    "$$P(y=Y)=P(R=0)P(M=1)=\\frac{4}{8}*\\frac{3}{8}=\\frac{3}{16}$$\n",
    "\n",
    "$$P(C=1 \\mid y=Y)= \\frac{1/16}{3/16}=\\frac{1}{3} $$\n",
    "\n",
    "## [Extending Naive Bayes, 4 points]\n",
    "\n",
    "Consider now, the following vector of attributes:\n",
    "\n",
    "* $x_1 = 1$ if customer is younger than 20 and 0 otherwise.\n",
    "* $x_2 = 1$ if customer is between 20 and 30 in age, and 0 otherwise.\n",
    "* $x_3 = 1$ if customer is older than 30 and 0 otherwise\n",
    "* $x_4 = 1$ if customer walks to work and 0 otherwise.\n",
    "\n",
    "Each vector of attributes has a label ''rich'' or ''poor''. Point out potential difficulties with your approach above to training using naive Bayes. Suggest and describe how to extend your naive Bayes method to this dataset.\n",
    "\n",
    "# ---------------------------------- Answer 2.1 ---------------------------------------\n",
    "\n",
    "Whenever a feature $x_1$ is set, we know that the features $x_2$ and $x_3$ is not (a customer cannot have two or more ages). In other words, these features are highly dependent and will therefore not work to train on. To solve this we can compose $x_1, x_2, x_3$ into one $x_{age}$ feature, for which can take on $x_{age}=(Y)oung\\mid (M)iddle \\mid (O)ld$. Now, our dataset consists of $x_{age}$ and $x_{walks}$ features, where each row labeled either ''Rich'' or ''Poor'' and is now possible to train on. For example, to calculate the probability $P(x_{age}=Y \\mid Rich)$, we count the number of rows where $x_{age}$ is ''Young'' and labeled ''Rich''. Since most countries unfortunately have child labour, we cannot assume that $x_1$ is dependent on $x_4$. If $x_{123}$ walks or not is probably more dependent on distance to work, health and wealth than age and thus we cannot make the assumption that they are dependent. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical problems\n",
    "\n",
    "## [Bayes classifier, 5 points]\n",
    "\n",
    "Dowload the dataset **\"dataset2.txt\"**. You can use the following code for example:\n",
    "```python\n",
    "from numpy import genfromtxt\n",
    "data = genfromtxt('dataset2.txt', delimiter=',')\n",
    "labels = data[:,-1]\n",
    "```\n",
    "The dataset contains $3$-dimensional data, $X$, generated from $2$ classes with labels, $y$ either $+1$ or $-1$.  Each row of $X$ and $y$ contain one observation and one label respectively.  There are $1000$ instances of each class. \n",
    "\n",
    "a. Assume that the class conditional density is spherical Gaussian, and both classes have equal prior. Write the expression for the Bayes (<span style=\"color:red\"> not **naive Bayes**</span>) classifier i.e. derive\n",
    "$$\n",
    "P(y_{new} = -1 | x_{new} , X, y ) \\\\\n",
    "P(y_{new} = +1 | x_{new} , X, y ) ~.\n",
    "$$\n",
    "\n",
    "It is useful to note that the dependence on training data $X, y$ for class $1$ can be expressed as: \n",
    "\n",
    "$$ \n",
    "P( x_{new} | y_{new} = 1, X, y) = P(x_{new} |\n",
    "\\hat{\\mu}_{1}, \\hat{\\sigma}^{2}_{1})\n",
    "$$\n",
    "\n",
    "where $\\hat{\\mu}_{1} \\in \\mathbb{R}^3$ and $\\hat{\\sigma}^{2}_{1}\\in \\mathbb{R}$ are MLE estimates for mean (3-dimensional) and variance based on training data with label $+1$ (and similarly for class 2 with label $-1$). \n",
    "\n",
    "# ---------------------------------- Answer 3.a ---------------------------------------\n",
    "\n",
    "The prior is the same for both $P(y_{new}=1)=P(y_{new}=-1)=\\frac{1}{2}$ and the likelihood can be, as given, rewritten as $P(x_{new} \\mid \\hat \\mu, \\hat \\sigma^2)$, hence\n",
    "\n",
    "$$P(y_{new} = 1 or -1 \\mid x_{new}, X) = \\frac{1}{2} P(x_{new} \\mid \\hat \\mu, \\hat \\sigma^2)$$\n",
    "\n",
    "Since the likelihood is a spherical Gaussian we can substitute with $N(x_{new} \\mid \\hat \\mu_i, \\hat \\sigma_i^2)$, thus $P(x_{new} \\mid \\hat \\mu, \\hat \\sigma^2) = \\frac{1}{2} N(x_{new} \\mid \\hat \\mu_i,\\hat \\sigma_i^2)$\n",
    "\n",
    "Finally, we substitute with the definition for a spherical Gaussian distribution where each subscript $i$ denotes the different estimates if $y_{new}=1$ or $y_{new}=-1$\n",
    "\n",
    "$$P(y_{new} = 1 \\mid x_{new} , X, y) = \\frac{1}{4\\pi^{3/2}\\hat \\sigma_{1}^2}\\exp{\\big[-\\frac{(x_{new}-\\hat \\mu_{1})^T(x_{new}-\\hat \\mu_{1})}{2\\hat \\sigma_{1}^2}\\big]}$$\n",
    "$$P(y_{new} = -1 \\mid x_{new} , X, y) = \\frac{1}{4\\pi^{3/2}\\hat \\sigma_{-1}^2}\\exp{\\big[-\\frac{(x_{new}-\\hat \\mu_{-1})^T(x_{new}-\\hat \\mu_{-1})}{2\\hat \\sigma_{-1}^2}\\big]}$$\n",
    "# ---------------------------------------------------------------------------------------\n",
    "\n",
    "b. Implement a function **sph_bayes()** which computes the probability of a new test point *Xtest* coming from class $1$ ($P1$) and class $2$ ($P2$). Finally, assign a label *Ytest* to the test point based on the probabilities $P1$ and $P2$.\n",
    "\n",
    "```python\n",
    "def sph_bayes(Xtest, ...): # other parameters needed.\n",
    "\n",
    "    return [P1, P2, Ytest]\n",
    "```\n",
    "c. Write a function **new_classifier()**\n",
    "\n",
    "```python\n",
    "def new_classifier(Xtest, mu1, mu2)\n",
    "    \n",
    "    return [Ytest]\n",
    "```\n",
    "which implements the following classifier,\n",
    "$$\n",
    "f(x) = \\mbox{sign}\\left(\\frac{(\\mu_1 - \\mu_2)^\\top (x - b) }{\\|\\mu_1 -  \\mu_2\\|_2} \\right)\n",
    "$$\n",
    "with $b = \\frac{1}{2}(\\mu_1 + \\mu_2)$.\n",
    "\n",
    "d. Report 5-fold cross validation error for both classifiers.\n",
    "\n",
    "## [DIGITS dataset classifer, 5 points]\n",
    "\n",
    "Load the DIGITS dataset:\n",
    "```python\n",
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()\n",
    "```\n",
    "This dataset contains $1797$ samples of ten handwritten digit classes. You can further query and visualize the dataset using the various attributes of the returned dictionary:\n",
    "```python\n",
    "data = digits.data\n",
    "print(data.shape)\n",
    "target_names = digits.target_names\n",
    "print (target_names)\n",
    "import matplotlib.pyplot as plt\n",
    "y = digits.target\n",
    "plt.matshow(digits.images[0])\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "a. Use **new_classifier()** designed previously to do binary classification between classes representing digits \"*5*\" and \"*8*\".\n",
    "\n",
    "b. Investigate an alternative feature function as described below:\n",
    "\n",
    "1. Scale each pixel value to range $[0, 1] $ from original gray-scale ($0-16$). \n",
    "2. Compute variance of each row and column of the image. This will give you a new feature vector of size $16$ i.e. \n",
    "\n",
    "$$ \n",
    "x' = \\left[ \\; Var(row_1)  , Var(row_2), \\ldots , Var(row_{8}), Var(col_1), \\ldots, Var(col_{8}) \\;\\right]^T\n",
    "$$\n",
    "\n",
    "c. Report $5$-fold cross validation results for parts $(a)$ and\n",
    "$(b)$ in a single table. What can you say about the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1610461880912632"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.model_selection import KFold\n",
    "from __future__ import division\n",
    "\n",
    "################################################# QUESTION 3B,C,D #####################################################\n",
    "# Import data\n",
    "data = np.genfromtxt('dataset2.txt', delimiter=',')\n",
    "\n",
    "# Get labels (y)\n",
    "labels = data[:,-1]\n",
    "\n",
    "# Get data where y=1 (X1) and y=-1 (X2) without last feature (y)\n",
    "X1 = np.delete(data[0:1000], 3, 1)\n",
    "X2 = np.delete(data[1001:2000], 3, 1)\n",
    "\n",
    "# Calculate mean for both\n",
    "mu1 = np.mean(X1,axis=0)\n",
    "mu2 = np.mean(X2,axis=0)\n",
    "\n",
    "# Calculate variance for both\n",
    "var1 = np.var(X1)\n",
    "var2 = np.var(X2)\n",
    "\n",
    "# Get a cov for both to use in multivariate function\n",
    "cov1 = np.diag([var1, var1, var1])\n",
    "cov2 = np.diag([var2, var2, var2])\n",
    "\n",
    "#### b)\n",
    "def sph_bayes(Xtest, mu1, mu2, cov1, cov2):\n",
    "    # Get posterior as a multivariate normal distribution\n",
    "    pdf1 = multivariate_normal.pdf(Xtest, mean=mu1, cov=cov1)\n",
    "    pdf2 = multivariate_normal.pdf(Xtest, mean=mu2, cov=cov2)\n",
    "    \n",
    "    # Define f as expected value for Xtext (given mu's and cov's)\n",
    "    f = 0\n",
    "    \n",
    "    # Calculate which is most likely\n",
    "    if pdf1 >= pdf2:\n",
    "        f = 1\n",
    "    else:\n",
    "        f = -1\n",
    "    \n",
    "    # Return pdf for each points\n",
    "    return [pdf1, pdf2, f]\n",
    "\n",
    "# Testing sph_bayes for a random vector x\n",
    "#print(sph_bayes([0.2,0.3,0.1],mu1,mu2,cov1,cov2))\n",
    "\n",
    "#### c)\n",
    "def new_classifier(Xtest, mu1, mu2):\n",
    "    # Calculate b\n",
    "    b = np.divide(np.add(mu1,mu2),2)\n",
    "    \n",
    "    # Calculate difference of mu's\n",
    "    mu_diff = np.subtract(mu1,mu2)\n",
    "    \n",
    "    # Calculate fraction of classifier\n",
    "    c = np.divide(np.dot(mu_diff.T,(np.subtract(Xtest,b))),np.linalg.norm(mu_diff))\n",
    "\n",
    "    # Return sign of c\n",
    "    return np.sign(c)\n",
    "\n",
    "# Testing new_classifier for a random vector x\n",
    "#print(new_classifier([0.2,0.2,0.2],mu1,mu2))\n",
    "\n",
    "\n",
    "################################################# QUESTION 4 #####################################################\n",
    "# Load dataset of digits\n",
    "digits = datasets.load_digits()\n",
    "data = digits.data\n",
    "\n",
    "#target_names = digits.target_names\n",
    "y = digits.target\n",
    "\n",
    "#### a)\n",
    "# Get all images with 5's and 8's\n",
    "img58 = [[],[]]\n",
    "for i in range(0,data.shape[0]):\n",
    "    if digits.target[i] == 5:\n",
    "        img58[0].append(data[i])\n",
    "    elif digits.target[i] == 8:\n",
    "        img58[1].append(data[i])\n",
    "        \n",
    "# Calculate mu for 5's and 8's\n",
    "mu5 = np.mean(img58[0], axis=0)\n",
    "mu8 = np.mean(img58[1], axis=0)\n",
    "\n",
    "# Now, given XTest (a random picked 8x8 image), we can use new_classifier(...) to determine it's a 5 (1) or 8 (-1)\n",
    "a_result = new_classifier(rand_data_img,mu5,mu8)\n",
    "\n",
    "### TESTING DONE with new_classifier: \n",
    "### Of 182 fives in img58, 2 are classified as eights (approx 1% error).\n",
    "### Of 174 eights in img58, 4 are classified as fives (approx 2% error).\n",
    "\n",
    "#### b.1) \n",
    "# Define a new dataset containing each new vector\n",
    "data_new_fives = []\n",
    "data_new_eights = []\n",
    "\n",
    "# Create new 16-feature variance dataset from every five and eight\n",
    "# Loop every five and eight images and create this new vector\n",
    "for i in range(0, data.shape[0]):\n",
    "    \n",
    "    # Do execute if 5 or 8, else continue\n",
    "    if digits.target[i] != 5 and digits.target[i] != 8:\n",
    "        continue\n",
    "\n",
    "    # Define data_new as data but rescale from 0-1\n",
    "    img_norm = digits.images[i]/16\n",
    "    \n",
    "    #### b.2)\n",
    "    # Define x_p to be x' with the given variances\n",
    "    x_p = np.zeros(16)\n",
    "\n",
    "    # Compute variance for 8 rows x 8 cols\n",
    "    for j in range(0,8):\n",
    "        x_p[j] = np.var(img_norm[j]) # Variance for row j\n",
    "        x_p[j+8] = np.var(img_norm.T[j]) # Variance for column j \n",
    "           \n",
    "    # Add x_p into data_new\n",
    "    if digits.target[i] == 5:\n",
    "        data_new_fives.append((x_p,5))\n",
    "    else:\n",
    "        data_new_eights.append((x_p,8))\n",
    "    \n",
    "# Calculate mu for this new dataset\n",
    "mu5_new = np.mean(data_new_fives, axis=0)\n",
    "mu8_new = np.mean(data_new_eights, axis=0)\n",
    "\n",
    "def crossValidationFunctionimg(newData):\n",
    "    \n",
    "    kf = KFold(n_splits = 5,shuffle = True) # find the index for splitting training and test sets for 5foldCV\n",
    "    \n",
    "    error = 0 # initial error value \n",
    "    \n",
    "    for trainingIndex, testIndex in kf.split(newData):\n",
    "\n",
    "        train, test = newData[trainingIndex],newData[testIndex]\n",
    "        m1 = []\n",
    "        m2 = []\n",
    "        for i in trainingIndex:\n",
    "            if digits.target[i] == 5:\n",
    "                m1.append(data[i])\n",
    "            elif digits.target[i] == 8:\n",
    "                m2.append(data[i])    \n",
    "            \n",
    "        mu1 = np.mean(m1,axis = 0)\n",
    "        mu2 = np.mean(m2,axis = 0)\n",
    "        \n",
    "        for i in testIndex:\n",
    "            pred = new_classifier(data[i], mu1, mu2)\n",
    "            check = 0\n",
    "            if digits.target[i] == 5:\n",
    "                check = 1\n",
    "            elif digits.target[i] == 8:\n",
    "                check = -1\n",
    "            \n",
    "            if pred != check:\n",
    "                error +=1 \n",
    "                \n",
    "\n",
    "    return(error/data.shape[0])/5\n",
    "\n",
    "def crossValidationFunctionimg(newData):\n",
    "    \n",
    "    kf = KFold(n_splits = 5,shuffle = True) # find the index for splitting training and test sets for 5foldCV\n",
    "    \n",
    "    error = 0 # initial error value \n",
    "    \n",
    "    for trainingIndex, testIndex in kf.split(newData):\n",
    "\n",
    "        train, test = newData[trainingIndex],newData[testIndex]\n",
    "        m1 = []\n",
    "        m2 = []\n",
    "        for i in trainingIndex:\n",
    "            if digits.target[i] == 5:\n",
    "                m1.append(data[i])\n",
    "            elif digits.target[i] == 8:\n",
    "                m2.append(data[i])    \n",
    "            \n",
    "        mu1 = np.mean(m1,axis = 0)\n",
    "        mu2 = np.mean(m2,axis = 0)\n",
    "        \n",
    "        for i in testIndex:\n",
    "            pred = new_classifier(data[i], mu1, mu2)\n",
    "            check = 0\n",
    "            if digits.target[i] == 5:\n",
    "                check = 1\n",
    "            elif digits.target[i] == 8:\n",
    "                check = -1\n",
    "            \n",
    "            if pred != check:\n",
    "                error +=1 \n",
    "                \n",
    "\n",
    "    return(error/data.shape[0])/5\n",
    "\n",
    "crossValidationFunctionimg(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
